{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0170946f",
   "metadata": {},
   "source": [
    "Use tf.summary.image record training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54de5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from preprocessing import parse_aug_fn, parse_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d369b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0]\n",
      " [0 2 1]\n",
      " [1 0 2]]\n"
     ]
    }
   ],
   "source": [
    "y_true = [2, 1, 0, 2, 2, 0, 1, 1]\n",
    "y_pred = [0, 1, 0, 2, 2, 0, 2, 1]\n",
    "cm = tf.math.confusion_matrix(y_true, y_pred, num_classes=3).numpy()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c247a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    產生一張Matplotlib圖片的Confusion matrix\n",
    "    :param cm (shape = [n,n]): 傳入confusion matrix\n",
    "    :param class_names (shape = [n]): 傳入類別名稱\n",
    "    \"\"\"\n",
    "    #標準化confusion matrix\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    #建立一個顯示畫面\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    #根據cm 的數值大小，在畫面中填入顏色\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    #設定標題\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    #刻度\n",
    "    tick_index = np.arange(len(class_names))\n",
    "    plt.ylim([-0.5, 2.5]) #matplotlib 3.1.1 to solve ylim bug between [0~2] range if not specified\n",
    "    #show class name in y-axis\n",
    "    plt.yticks(tick_index, class_names)\n",
    "    #show class name in x-axis and rotate 45 degrees to prevent word stacking together\n",
    "    plt.xticks(tick_index, class_names, rotation=45)\n",
    "    #在圖片右邊產生一條顏色刻度條\n",
    "    plt.colorbar()\n",
    "    \n",
    "    #在每一格Confusion matrix 輸入預測百分比\n",
    "    threshold = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            #if color in block is too deep, use white words, otherwise use black words\n",
    "            color = \"white\" if cm[i,j] >threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    #將圖片位置調整，避免x or y axis 文字被遮擋\n",
    "    plt.tight_layout()\n",
    "    return figure\n",
    "\n",
    "img = plot_confusion_matrix(cm, [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45258be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"將Matplotlib plot的圖片轉TensorFlow的張量格式，然後才能記錄到TensorBoard\"\"\"\n",
    "    # 將Matplotlib plot的圖片以PNG的格式儲存到記憶體中\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # 關閉plt圖片，防止圖片直接顯示在Jupyter notebook介面中\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # 將記憶體中的資料轉成TensorFlow格式\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e227f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrix(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, log_dir, test_data, class_name):\n",
    "        super(ConfusionMatrix, self).__init__()\n",
    "        self.log_dir = log_dir\n",
    "        self.test_data = test_data\n",
    "        self.class_names = class_name\n",
    "        self.num_classes = len(class_name)\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        path = os.path.join(self.log_dir, 'confusion_matrix')\n",
    "        #建立TensorBoard 紀錄檔\n",
    "        self.writer = tf.summary.create_file_writer(path)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        #計算Confusion Matrix\n",
    "        total_cm = np.zeros([10, 10])\n",
    "        for x, y_true in self.test_data:\n",
    "            y_pred = self.model.predict(x)\n",
    "            y_pred = np.argmax(y_pred, axis=1)\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "            cm = tf.math.confusion_matrix(y_true, y_pred, num_classes=self.num_classes).numpy()\n",
    "        \n",
    "            total_cm += cm\n",
    "        \n",
    "        #將Confusion matrix 轉成Matplotlib圖片\n",
    "        figure = plot_confusion_matrix(total_cm, class_names=self.class_names)\n",
    "        # 將Matplotlib圖片轉成TensorFlow型式的圖片\n",
    "        cm_image = plot_to_image(figure)\n",
    "        \n",
    "        # 將圖片紀錄在TensorBoard log中\n",
    "        with self.writer.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67836b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將train Data重新分成9:1等分，分別分給train data, valid data\n",
    "train_split, valid_split = ['train[:90%]', 'train[90%:]']\n",
    "# 取得訓練數據，並順便讀取data的資訊\n",
    "train_data, info = tfds.load(\"cifar10\", split=train_split, with_info=True)\n",
    "# 取得驗證數據\n",
    "valid_data = tfds.load(\"cifar10\", split=valid_split)\n",
    "# 取得測試數據\n",
    "test_data = tfds.load(\"cifar10\", split=tfds.Split.TEST)\n",
    "# 取得CIFAR-10數據集的類別\n",
    "class_name = info.features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1bec182",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE  # 自動調整模式\n",
    "batch_size = 64  # 批次大小\n",
    "train_num = int(info.splits['train'].num_examples / 10) * 9  # 訓練資料數量\n",
    "\n",
    "train_data = train_data.shuffle(train_num)  # 打散資料集\n",
    "# 載入預處理「 parse_aug_fn」function，cpu數量為自動調整模式\n",
    "train_data = train_data.map(map_func=parse_aug_fn, num_parallel_calls=AUTOTUNE)\n",
    "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
    "train_data = train_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# 載入預處理「 parse_fn」function，cpu數量為自動調整模式\n",
    "valid_data = valid_data.map(map_func=parse_fn, num_parallel_calls=AUTOTUNE)\n",
    "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
    "valid_data = valid_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# 載入預處理「 parse_fn」function，cpu數量為自動調整模式\n",
    "test_data = test_data.map(map_func=parse_fn, num_parallel_calls=AUTOTUNE)\n",
    "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
    "test_data = test_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b207227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model-1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 30, 30, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 128)         295040    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 64)          73792     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                200768    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 941,066\n",
      "Trainable params: 941,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(64, 3, activation='relu', kernel_initializer='glorot_uniform')(inputs)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10)(x)\n",
    "# 建立網路模型(將輸入到輸出所有經過的網路層連接起來)\n",
    "model_1 = keras.Model(inputs, outputs, name='model-1')\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7447f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存訓練記錄檔\n",
    "logs_dirs = 'lab7-logs-images'\n",
    "model_cbk = keras.callbacks.TensorBoard(logs_dirs)\n",
    "# 儲存Confusion matrix圖片\n",
    "save_cm = ConfusionMatrix(logs_dirs, test_data, class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e16c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(keras.optimizers.Adam(), \n",
    "                loss=keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "                metrics=[keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4260d4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "704/704 [==============================] - 40s 57ms/step - loss: 2.0659 - categorical_accuracy: 0.2210 - val_loss: 0.0000e+00 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 25s 35ms/step - loss: 1.8495 - categorical_accuracy: 0.3228 - val_loss: 1.6143 - val_categorical_accuracy: 0.4224\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 1.7306 - categorical_accuracy: 0.3719 - val_loss: 1.4715 - val_categorical_accuracy: 0.4752\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 1.6386 - categorical_accuracy: 0.4144 - val_loss: 1.2835 - val_categorical_accuracy: 0.5438\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 24s 33ms/step - loss: 1.5569 - categorical_accuracy: 0.4443 - val_loss: 1.2118 - val_categorical_accuracy: 0.5634\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 1.4948 - categorical_accuracy: 0.4733 - val_loss: 1.1431 - val_categorical_accuracy: 0.5898\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 1.4378 - categorical_accuracy: 0.4934 - val_loss: 1.1014 - val_categorical_accuracy: 0.6102\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 1.3920 - categorical_accuracy: 0.5127 - val_loss: 1.0618 - val_categorical_accuracy: 0.6138\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 1.3622 - categorical_accuracy: 0.5252 - val_loss: 1.0457 - val_categorical_accuracy: 0.6300\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 24s 33ms/step - loss: 1.3254 - categorical_accuracy: 0.5388 - val_loss: 0.9957 - val_categorical_accuracy: 0.6438\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 1.2998 - categorical_accuracy: 0.5444 - val_loss: 0.9786 - val_categorical_accuracy: 0.6542\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 1.2782 - categorical_accuracy: 0.5557 - val_loss: 0.9308 - val_categorical_accuracy: 0.6706\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 25s 35ms/step - loss: 1.2476 - categorical_accuracy: 0.5636 - val_loss: 0.9846 - val_categorical_accuracy: 0.6570\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 24s 35ms/step - loss: 1.2277 - categorical_accuracy: 0.5759 - val_loss: 0.9383 - val_categorical_accuracy: 0.6704\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 25s 35ms/step - loss: 1.2023 - categorical_accuracy: 0.5855 - val_loss: 0.8903 - val_categorical_accuracy: 0.6802\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 25s 36ms/step - loss: 1.1829 - categorical_accuracy: 0.5881 - val_loss: 0.8914 - val_categorical_accuracy: 0.6834\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 1.1709 - categorical_accuracy: 0.5946 - val_loss: 0.8962 - val_categorical_accuracy: 0.6874\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 25s 35ms/step - loss: 1.1603 - categorical_accuracy: 0.6012 - val_loss: 0.8576 - val_categorical_accuracy: 0.6996\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 1.1443 - categorical_accuracy: 0.6086 - val_loss: 0.8265 - val_categorical_accuracy: 0.7150\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 1.1173 - categorical_accuracy: 0.6132 - val_loss: 0.9101 - val_categorical_accuracy: 0.6860\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 1.1134 - categorical_accuracy: 0.6165 - val_loss: 0.8378 - val_categorical_accuracy: 0.7082\n",
      "Epoch 22/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 1.1137 - categorical_accuracy: 0.6161 - val_loss: 0.8741 - val_categorical_accuracy: 0.7040\n",
      "Epoch 23/100\n",
      "704/704 [==============================] - 25s 35ms/step - loss: 1.0830 - categorical_accuracy: 0.6311 - val_loss: 0.8416 - val_categorical_accuracy: 0.7142\n",
      "Epoch 24/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 1.0802 - categorical_accuracy: 0.6310 - val_loss: 0.8225 - val_categorical_accuracy: 0.7202\n",
      "Epoch 25/100\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 1.0613 - categorical_accuracy: 0.6382 - val_loss: 0.8109 - val_categorical_accuracy: 0.7188\n",
      "Epoch 26/100\n",
      "704/704 [==============================] - 24s 33ms/step - loss: 1.0625 - categorical_accuracy: 0.6389 - val_loss: 0.8449 - val_categorical_accuracy: 0.7070\n",
      "Epoch 27/100\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 1.0506 - categorical_accuracy: 0.6400 - val_loss: 0.7497 - val_categorical_accuracy: 0.7408\n",
      "Epoch 28/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 1.0475 - categorical_accuracy: 0.6438 - val_loss: 0.8589 - val_categorical_accuracy: 0.7004\n",
      "Epoch 29/100\n",
      "704/704 [==============================] - 25s 36ms/step - loss: 1.0359 - categorical_accuracy: 0.6483 - val_loss: 0.7633 - val_categorical_accuracy: 0.7426\n",
      "Epoch 30/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 1.0280 - categorical_accuracy: 0.6508 - val_loss: 0.7508 - val_categorical_accuracy: 0.7468\n",
      "Epoch 31/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 1.0113 - categorical_accuracy: 0.6552 - val_loss: 0.7819 - val_categorical_accuracy: 0.7250\n",
      "Epoch 32/100\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 1.0049 - categorical_accuracy: 0.6577 - val_loss: 0.7773 - val_categorical_accuracy: 0.7370\n",
      "Epoch 33/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.9969 - categorical_accuracy: 0.6603 - val_loss: 0.7491 - val_categorical_accuracy: 0.7456\n",
      "Epoch 34/100\n",
      "704/704 [==============================] - 24s 33ms/step - loss: 0.9942 - categorical_accuracy: 0.6604 - val_loss: 0.7319 - val_categorical_accuracy: 0.7522\n",
      "Epoch 35/100\n",
      "704/704 [==============================] - 26s 37ms/step - loss: 0.9887 - categorical_accuracy: 0.6649 - val_loss: 0.7346 - val_categorical_accuracy: 0.7430\n",
      "Epoch 36/100\n",
      "704/704 [==============================] - 24s 35ms/step - loss: 0.9590 - categorical_accuracy: 0.6748 - val_loss: 0.7306 - val_categorical_accuracy: 0.7514\n",
      "Epoch 37/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.9590 - categorical_accuracy: 0.6746 - val_loss: 0.7601 - val_categorical_accuracy: 0.7414\n",
      "Epoch 38/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.9622 - categorical_accuracy: 0.6764 - val_loss: 0.7070 - val_categorical_accuracy: 0.7616\n",
      "Epoch 39/100\n",
      "704/704 [==============================] - 25s 35ms/step - loss: 0.9547 - categorical_accuracy: 0.6758 - val_loss: 0.7282 - val_categorical_accuracy: 0.7558\n",
      "Epoch 40/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.9528 - categorical_accuracy: 0.6772 - val_loss: 0.6936 - val_categorical_accuracy: 0.7660\n",
      "Epoch 41/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.9528 - categorical_accuracy: 0.6795 - val_loss: 0.7223 - val_categorical_accuracy: 0.7492\n",
      "Epoch 42/100\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 0.9398 - categorical_accuracy: 0.6838 - val_loss: 0.7134 - val_categorical_accuracy: 0.7496\n",
      "Epoch 43/100\n",
      "704/704 [==============================] - 24s 33ms/step - loss: 0.9350 - categorical_accuracy: 0.6857 - val_loss: 0.7067 - val_categorical_accuracy: 0.7632\n",
      "Epoch 44/100\n",
      "704/704 [==============================] - 26s 36ms/step - loss: 0.9259 - categorical_accuracy: 0.6844 - val_loss: 0.6948 - val_categorical_accuracy: 0.7566\n",
      "Epoch 45/100\n",
      "704/704 [==============================] - 24s 33ms/step - loss: 0.9283 - categorical_accuracy: 0.6872 - val_loss: 0.6920 - val_categorical_accuracy: 0.7620\n",
      "Epoch 46/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.9150 - categorical_accuracy: 0.6953 - val_loss: 0.6807 - val_categorical_accuracy: 0.7696\n",
      "Epoch 47/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.9283 - categorical_accuracy: 0.6904 - val_loss: 0.6776 - val_categorical_accuracy: 0.7678\n",
      "Epoch 48/100\n",
      "704/704 [==============================] - 24s 33ms/step - loss: 0.9090 - categorical_accuracy: 0.6942 - val_loss: 0.6888 - val_categorical_accuracy: 0.7696\n",
      "Epoch 49/100\n",
      "704/704 [==============================] - 24s 35ms/step - loss: 0.9041 - categorical_accuracy: 0.6963 - val_loss: 0.7000 - val_categorical_accuracy: 0.7624\n",
      "Epoch 50/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.9028 - categorical_accuracy: 0.6969 - val_loss: 0.7350 - val_categorical_accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8921 - categorical_accuracy: 0.7005 - val_loss: 0.6756 - val_categorical_accuracy: 0.7778\n",
      "Epoch 52/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8949 - categorical_accuracy: 0.7006 - val_loss: 0.6825 - val_categorical_accuracy: 0.7648\n",
      "Epoch 53/100\n",
      "704/704 [==============================] - 25s 35ms/step - loss: 0.8940 - categorical_accuracy: 0.6994 - val_loss: 0.6889 - val_categorical_accuracy: 0.7652\n",
      "Epoch 54/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8878 - categorical_accuracy: 0.7018 - val_loss: 0.7386 - val_categorical_accuracy: 0.7580\n",
      "Epoch 55/100\n",
      "704/704 [==============================] - 27s 38ms/step - loss: 0.8894 - categorical_accuracy: 0.6995 - val_loss: 0.6802 - val_categorical_accuracy: 0.7724\n",
      "Epoch 56/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8770 - categorical_accuracy: 0.7057 - val_loss: 0.7156 - val_categorical_accuracy: 0.7622\n",
      "Epoch 57/100\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 0.8746 - categorical_accuracy: 0.7075 - val_loss: 0.6911 - val_categorical_accuracy: 0.7646\n",
      "Epoch 58/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8714 - categorical_accuracy: 0.7079 - val_loss: 0.6739 - val_categorical_accuracy: 0.7756\n",
      "Epoch 59/100\n",
      "704/704 [==============================] - 25s 35ms/step - loss: 0.8599 - categorical_accuracy: 0.7116 - val_loss: 0.6678 - val_categorical_accuracy: 0.7736\n",
      "Epoch 60/100\n",
      "704/704 [==============================] - 25s 36ms/step - loss: 0.8726 - categorical_accuracy: 0.7087 - val_loss: 0.6597 - val_categorical_accuracy: 0.7760\n",
      "Epoch 61/100\n",
      "704/704 [==============================] - 26s 36ms/step - loss: 0.8610 - categorical_accuracy: 0.7117 - val_loss: 0.6662 - val_categorical_accuracy: 0.7732\n",
      "Epoch 62/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8621 - categorical_accuracy: 0.7136 - val_loss: 0.6803 - val_categorical_accuracy: 0.7740\n",
      "Epoch 63/100\n",
      "704/704 [==============================] - 25s 35ms/step - loss: 0.8615 - categorical_accuracy: 0.7152 - val_loss: 0.6500 - val_categorical_accuracy: 0.7798\n",
      "Epoch 64/100\n",
      "704/704 [==============================] - 24s 33ms/step - loss: 0.8594 - categorical_accuracy: 0.7144 - val_loss: 0.6240 - val_categorical_accuracy: 0.7848\n",
      "Epoch 65/100\n",
      "704/704 [==============================] - 24s 35ms/step - loss: 0.8498 - categorical_accuracy: 0.7149 - val_loss: 0.6711 - val_categorical_accuracy: 0.7782\n",
      "Epoch 66/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8514 - categorical_accuracy: 0.7182 - val_loss: 0.6593 - val_categorical_accuracy: 0.7814\n",
      "Epoch 67/100\n",
      "704/704 [==============================] - 26s 38ms/step - loss: 0.8445 - categorical_accuracy: 0.7198 - val_loss: 0.6610 - val_categorical_accuracy: 0.7792\n",
      "Epoch 68/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8492 - categorical_accuracy: 0.7160 - val_loss: 0.6269 - val_categorical_accuracy: 0.7934\n",
      "Epoch 69/100\n",
      "704/704 [==============================] - 24s 35ms/step - loss: 0.8385 - categorical_accuracy: 0.7221 - val_loss: 0.6401 - val_categorical_accuracy: 0.7778\n",
      "Epoch 70/100\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 0.8384 - categorical_accuracy: 0.7175 - val_loss: 0.6524 - val_categorical_accuracy: 0.7802\n",
      "Epoch 71/100\n",
      "704/704 [==============================] - 24s 35ms/step - loss: 0.8332 - categorical_accuracy: 0.7226 - val_loss: 0.6397 - val_categorical_accuracy: 0.7878\n",
      "Epoch 72/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8254 - categorical_accuracy: 0.7246 - val_loss: 0.6970 - val_categorical_accuracy: 0.7748\n",
      "Epoch 73/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8357 - categorical_accuracy: 0.7232 - val_loss: 0.6526 - val_categorical_accuracy: 0.7826\n",
      "Epoch 74/100\n",
      "704/704 [==============================] - 25s 35ms/step - loss: 0.8262 - categorical_accuracy: 0.7258 - val_loss: 0.6424 - val_categorical_accuracy: 0.7858\n",
      "Epoch 75/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8364 - categorical_accuracy: 0.7227 - val_loss: 0.6458 - val_categorical_accuracy: 0.7816\n",
      "Epoch 76/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8240 - categorical_accuracy: 0.7248 - val_loss: 0.6366 - val_categorical_accuracy: 0.7866\n",
      "Epoch 77/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8261 - categorical_accuracy: 0.7258 - val_loss: 0.6250 - val_categorical_accuracy: 0.7926\n",
      "Epoch 78/100\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 0.8197 - categorical_accuracy: 0.7285 - val_loss: 0.6668 - val_categorical_accuracy: 0.7756\n",
      "Epoch 79/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8205 - categorical_accuracy: 0.7254 - val_loss: 0.6334 - val_categorical_accuracy: 0.7832\n",
      "Epoch 80/100\n",
      "704/704 [==============================] - 24s 35ms/step - loss: 0.8067 - categorical_accuracy: 0.7292 - val_loss: 0.6718 - val_categorical_accuracy: 0.7730\n",
      "Epoch 81/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8151 - categorical_accuracy: 0.7293 - val_loss: 0.6577 - val_categorical_accuracy: 0.7828\n",
      "Epoch 82/100\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 0.8031 - categorical_accuracy: 0.7336 - val_loss: 0.6857 - val_categorical_accuracy: 0.7780\n",
      "Epoch 83/100\n",
      "704/704 [==============================] - 28s 40ms/step - loss: 0.8044 - categorical_accuracy: 0.7324 - val_loss: 0.6600 - val_categorical_accuracy: 0.7812\n",
      "Epoch 84/100\n",
      "704/704 [==============================] - 24s 35ms/step - loss: 0.8043 - categorical_accuracy: 0.7311 - val_loss: 0.6521 - val_categorical_accuracy: 0.7888\n",
      "Epoch 85/100\n",
      "704/704 [==============================] - 25s 35ms/step - loss: 0.8070 - categorical_accuracy: 0.7316 - val_loss: 0.6728 - val_categorical_accuracy: 0.7824\n",
      "Epoch 86/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.7996 - categorical_accuracy: 0.7340 - val_loss: 0.6723 - val_categorical_accuracy: 0.7820\n",
      "Epoch 87/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8055 - categorical_accuracy: 0.7354 - val_loss: 0.6422 - val_categorical_accuracy: 0.7896\n",
      "Epoch 88/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.7931 - categorical_accuracy: 0.7363 - val_loss: 0.6483 - val_categorical_accuracy: 0.7824\n",
      "Epoch 89/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.8006 - categorical_accuracy: 0.7362 - val_loss: 0.6488 - val_categorical_accuracy: 0.7864\n",
      "Epoch 90/100\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 0.7987 - categorical_accuracy: 0.7345 - val_loss: 0.6365 - val_categorical_accuracy: 0.7932\n",
      "Epoch 91/100\n",
      "704/704 [==============================] - 25s 36ms/step - loss: 0.7890 - categorical_accuracy: 0.7379 - val_loss: 0.6455 - val_categorical_accuracy: 0.7874\n",
      "Epoch 92/100\n",
      "704/704 [==============================] - 25s 36ms/step - loss: 0.7941 - categorical_accuracy: 0.7370 - val_loss: 0.6712 - val_categorical_accuracy: 0.7830\n",
      "Epoch 93/100\n",
      "704/704 [==============================] - 26s 37ms/step - loss: 0.7924 - categorical_accuracy: 0.7375 - val_loss: 0.6434 - val_categorical_accuracy: 0.7928\n",
      "Epoch 94/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.7950 - categorical_accuracy: 0.7402 - val_loss: 0.6765 - val_categorical_accuracy: 0.7940\n",
      "Epoch 95/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.7800 - categorical_accuracy: 0.7385 - val_loss: 0.6442 - val_categorical_accuracy: 0.7930\n",
      "Epoch 96/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.7806 - categorical_accuracy: 0.7417 - val_loss: 0.6381 - val_categorical_accuracy: 0.7890\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 24s 34ms/step - loss: 0.7942 - categorical_accuracy: 0.7392 - val_loss: 0.6395 - val_categorical_accuracy: 0.7974\n",
      "Epoch 98/100\n",
      "704/704 [==============================] - 24s 33ms/step - loss: 0.7880 - categorical_accuracy: 0.7399 - val_loss: 0.6362 - val_categorical_accuracy: 0.7954\n",
      "Epoch 99/100\n",
      "704/704 [==============================] - 24s 34ms/step - loss: 0.7751 - categorical_accuracy: 0.7432 - val_loss: 0.6354 - val_categorical_accuracy: 0.7950\n",
      "Epoch 100/100\n",
      "704/704 [==============================] - 24s 35ms/step - loss: 0.7879 - categorical_accuracy: 0.7424 - val_loss: 0.6117 - val_categorical_accuracy: 0.8006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bf545e99e8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(train_data,\n",
    "            epochs=100, \n",
    "            validation_data=valid_data,\n",
    "            callbacks=[model_cbk, save_cm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6059d069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
